import os
import uuid
import torch
import clip
from PIL import Image
from flask import Flask, request, jsonify, render_template, send_file, session
from ultralytics import YOLO
from google.generativeai import GenerativeModel, configure
from dotenv import load_dotenv

# ğŸ”¥ CORS ì¶”ê°€
from flask_cors import CORS

# ===================== .env ë¡œë“œ =====================
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ===================== ê²½ë¡œ =====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
OUTPUT_DIR = os.path.join(BASE_DIR, "output")
SEED_BASE = os.path.join(BASE_DIR, "list_image")

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ===================== Gemini ì„¤ì • =====================
if not GOOGLE_API_KEY:
    raise ValueError(" GOOGLE_API_KEYê°€ .env ì— ì—†ìŠµë‹ˆë‹¤!")

configure(api_key=GOOGLE_API_KEY)
gemini_model = GenerativeModel("gemini-2.5-flash")

# ===================== ëª¨ë¸ =====================
yolo_model = YOLO(os.path.join(BASE_DIR, "yolov8n.pt"))
device = "cuda" if torch.cuda.is_available() else "cpu"
clip_model, preprocess = clip.load("ViT-B/32", device=device)

# ===================== Seed ì„ë² ë”© =====================
seed_embeddings = []


def load_seed_embeddings():
    for class_name in os.listdir(SEED_BASE):
        class_path = os.path.join(SEED_BASE, class_name)
        if not os.path.isdir(class_path):
            continue

        for file in os.listdir(class_path):
            full_path = os.path.join(class_path, file)
            try:
                img = preprocess(Image.open(full_path)).unsqueeze(0).to(device)
                with torch.no_grad():
                    emb = clip_model.encode_image(img)
                emb = emb / emb.norm()

                seed_embeddings.append(
                    {
                        "class": class_name,
                        "filename": file,
                        "path": full_path,
                        "relative_url": f"/list_image/{class_name}/{file}".replace("\\", "/"),
                        "embedding": emb,
                    }
                )
            except:
                continue


load_seed_embeddings()


def find_top3(target_embedding, target_class):
    sims = []
    for item in seed_embeddings:
        if item["class"] != target_class:
            continue

        emb = item["embedding"]
        emb = emb / emb.norm()
        sim = float((target_embedding @ emb.T).item())

        sims.append(
            {
                "filename": item["filename"],
                "similarity": sim,
                "url": item["relative_url"],
            }
        )

    sims = sorted(sims, key=lambda x: x["similarity"], reverse=True)
    return sims[:3]


# ===================== Flask ì•± =====================
app = Flask(__name__)
app.secret_key = "abcd1234"

# ğŸ”¥ğŸ”¥ CORS ì„¤ì • (React 3000 í—ˆìš©)
CORS(
    app,
    supports_credentials=True,
    resources={
        r"/*": {
            "origins": [
                "http://localhost:3000",
                "http://127.0.0.1:3000",
            ]
        }
    },
)

# ===================== í´ë˜ìŠ¤ ë§¤í•‘ =====================
class_map = {
    "bed": "bed",
    "chair": "chair",
    "couch": "couch",
    "dining table": "dining_table",
    "dining_table": "dining_table",
    "tv": "tv",
    "microwave": "microwave",
    "microwave": "range",
    "refrigerator": "refrigerator",
    "fridge": "refrigerator",
    "refrigerator": "fridge",
    "sofa": "couch",
    "sofa chair": "couch",
    "ibul": "bed",
    "blanket": "bed",
    "drawer": "bed",
    "cabinet": "bed",
    "table": "dining_table",
    "stand": "dining_table",
    "tree": "potted plant",
    "ì „ìë ˆì¸ì§€": "range",
    "ì „ìë ˆì¸ì§€": "microwave",
    "ì¹¨ëŒ€": "bed",
    "ì´ë¶ˆ": "bed",
    "ë‹´ìš”": "bed",
    "ì˜ì": "chair",
    "ì²´ì–´": "chair",
    "ì†ŒíŒŒ": "couch",
    "ì‡¼íŒŒ": "couch",
    "ì‹íƒ": "dining_table",
    "í…Œì´ë¸”": "dining_table",
    "ëƒ‰ì¥ê³ ": "refrigerator",
    "ëƒ‰ì¥ê³ ": "fridge",
    "í‹°ë¹„": "tv",
    "ìŠ¤íƒ ë“œ": "dining_table",
    "í™”ë¶„": "potted plant",
    "ë‚˜ë¬´": "potted plant",
    "íŠ¸ë¦¬": "potted plant",
}

# ë‚´ë¶€ í´ë˜ìŠ¤ëª… â†’ í•œê¸€ í‘œì‹œ
class_display = {
    "bed": "ì¹¨ëŒ€",
    "chair": "ì˜ì",
    "couch": "ì†ŒíŒŒ",
    "dining_table": "ì‹íƒ",
    "tv": "í‹°ë¹„",
    "potted_plant": "í™”ë¶„",
    "refrigerator": "ëƒ‰ì¥ê³ ",
    "microwave": "ì „ìë ˆì¸ì§€",
    "fridge": "ëƒ‰ì¥ê³ ",
    "range": "ì „ìë ˆì¸ì§€",
}

# ===================== ë¼ìš°íŠ¸ =====================


@app.route("/")
def index():
    return jsonify({"message": "Flask API Server is running"})

# âœ… Reactì—ì„œ ì“¸ health ì²´í¬
@app.route("/health")
def health():
    return jsonify({"status": "ok"})


@app.route("/localfile/<path:filepath>")
def localfile(filepath):
    return send_file(filepath)


@app.route("/list_image/<cls>/<filename>")
def list_image(cls, filename):
    return send_file(os.path.join(SEED_BASE, cls, filename))


# ===================== ì´ë¯¸ì§€ ê°ì§€ =====================
@app.route("/detect", methods=["POST"])
def detect():
    if "image" not in request.files:
        return jsonify({"error": "ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    file = request.files["image"]
    img_id = f"{uuid.uuid4()}.jpg"
    save_path = os.path.join(UPLOAD_DIR, img_id)
    file.save(save_path)

    results = yolo_model(save_path)[0]
    results.save(filename=os.path.join(OUTPUT_DIR, img_id))

    class_counter = {}
    detected_objects = []
    detected_classes = set()

    for idx, box in enumerate(results.boxes):
        cls_id = int(box.cls.item())
        cls_name = results.names[cls_id]
        detected_classes.add(cls_name)

        if cls_name not in class_counter:
            class_counter[cls_name] = 1
        else:
            class_counter[cls_name] += 1

        detected_objects.append(
            {
                "id": f"{cls_name}_{class_counter[cls_name]}",
                "class": cls_name,
                "bbox": [int(x) for x in box.xyxy.tolist()[0]],
            }
        )

    # YOLO ê°ì§€ëª… â†’ class_map ì ìš©
    normalized_detected = []
    for cls in detected_classes:
        key = cls.lower().replace(" ", "_")
        normalized_detected.append(class_map.get(key, key))

    session["detected_classes"] = normalized_detected
    session["last_step"] = "AFTER_DETECT"

    # ê°ì§€ í´ë˜ìŠ¤ í•œê¸€ í‘œì‹œ
    detected_display = [class_display.get(cls, cls) for cls in normalized_detected]

    return jsonify(
        {
            "upload_image": f"/localfile/{save_path}".replace("\\", "/"),
            "detected": detected_objects,
            "classes": normalized_detected,
            "classes_display": detected_display,
        }
    )


# ===================== ì±—ë´‡ =====================
@app.route("/chat", methods=["POST"])
def chat():
    user_text = request.json.get("message", "").strip()
    detected_classes = session.get("detected_classes", [])
    last_step = session.get("last_step", "WAIT_IMAGE")

    # ===========================
    # í´ë˜ìŠ¤ ë§¤í•‘ ì²˜ë¦¬
    # ===========================
    key = user_text.lower().replace(" ", "_")
    normalized = class_map.get(key, key)

    # ===========================
    # ì¶”ì²œ ì•„ì´í…œ ì¶”ì¶œ
    # ===========================
    top3_items = []
    if normalized in detected_classes:
        target_emb = None
        for item in seed_embeddings:
            if item["class"] == normalized:
                target_emb = item["embedding"]
                break

        if target_emb is not None:
            top3_items = find_top3(target_emb, normalized)
            for item in top3_items:
                item["display_name"] = class_display.get(normalized, normalized)

    # ===========================
    # SYSTEM PROMPT êµ¬ì„±
    # ===========================
    system_prompt = """
ë„ˆëŠ” ì¸í…Œë¦¬ì–´ ê°€êµ¬ ì¶”ì²œ ì±—ë´‡ì´ë‹¤.

ê·œì¹™:
1. ì‚¬ìš©ìê°€ ë„£ì€ ì´ë¯¸ì§€ì—ì„œ ë‚˜ì˜¨ ê°€êµ¬ë¥¼ ì•Œë ¤ì£¼ê¸°.
2. ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì´ì–´ì„œ í•˜ë¼:
   - 'ì´ ì¶”ì²œì´ ë§ˆìŒì— ë“œì‹œë‚˜ìš”?'
   - 'ë‹¤ë¥¸ ì œí’ˆë„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”?'
   - 'ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ë„ ë³´ì—¬ë“œë¦´ê¹Œìš”?'
3. ì¶”ì²œ í›„ì— ì§ˆë¬¸ ì—†ì´ ëŒ€í™”ë¥¼ ëë‚´ëŠ” í˜•íƒœë¡œ ë‹µë³€í•˜ì§€ ë§ ê²ƒ. ë‹¨, 3ë¬¸ì¥ì„ ë„˜ê¸°ì§€ ë§ ê²ƒ.
"""

    # top3 ì¶”ì²œì´ ìˆì„ ê²½ìš° â†’ AIì—ê²Œ ì „ë‹¬
    recommendations_text = ""
    if top3_items:
        recommendations_text += "\nì¶”ì²œí•  ê°€êµ¬ ì´ë¯¸ì§€ ëª©ë¡:\n"
        for idx, item in enumerate(top3_items, 1):
            recommendations_text += f"- {idx}. {item['display_name']} (íŒŒì¼: {item['filename']})\n"

    # ===========================
    # AI í”„ë¡¬í”„íŠ¸ ìƒì„±
    # ===========================
    prompt = f"""
{system_prompt}

ì‚¬ìš©ì ì…ë ¥: {user_text}

{recommendations_text}
"""

    # ===========================
    # Gemini í˜¸ì¶œ
    # ===========================
    response = gemini_model.generate_content(prompt)
    reply = response.text

    # ===========================
    # JSON ì‘ë‹µ
    # ===========================
    result = {"reply": reply}
    if top3_items:
        result["top3"] = top3_items

    return jsonify(result)


# ===================== ì•± ì‹¤í–‰ =====================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
